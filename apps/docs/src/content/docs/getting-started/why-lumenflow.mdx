---
title: Why LumenFlow?
description: Why your AI agents need a governance kernel
---

import { Aside, Card, CardGrid } from '@astrojs/starlight/components';

AI agents are powerful. They can read files, write code, call APIs, and deploy services. But without governance, they operate in a trust vacuum — no audit trail, no policy enforcement, no scope boundaries. When an agent makes a mistake, there is no proof of what happened and no mechanism to prevent it next time.

LumenFlow solves this by inserting a **governance kernel** between agents and the world.

## The Problem

Today's AI agent workflows rely on one of three approaches, all of which fail at scale:

<CardGrid>
  <Card title="No governance" icon="warning">
    Agents run with full access. You hope they follow instructions. No audit trail, no rollback, no
    proof of what happened.
  </Card>
  <Card title="Prompt-only trust" icon="document">
    Frameworks like LangChain and CrewAI define agent roles in prompts. But prompts are suggestions,
    not enforcement — agents can ignore them.
  </Card>
  <Card title="CI-only enforcement" icon="setting">
    GitHub Actions and CI pipelines catch issues after the fact. By the time a check fails, the
    agent has already written files, made commits, and potentially caused damage.
  </Card>
</CardGrid>

None of these approaches provide **real-time governance** — enforcement that happens _before_ each action, not after.

## Four Kernel Guarantees

LumenFlow's kernel provides four guarantees that cannot be bypassed:

### 1. Scope Intersection

Every agent action is checked against a 4-level permission model: workspace, lane, task, and tool scopes must **all agree** before execution proceeds. If any level denies access, the action is blocked.

```
Agent requests: file:write("src/auth/login.ts")
  ✓ Workspace scope: src/** allowed
  ✓ Lane scope: src/auth/** allowed (Framework: Core lane)
  ✓ Task scope: src/auth/** allowed (WU code_paths)
  ✓ Tool scope: file:write allowed
  → PERMITTED
```

### 2. Deny-Wins Policies

Policies are evaluated in a layered cascade. A restrictive policy at **any level** cannot be loosened by a lower level. This means:

- A workspace policy that denies `.env` access cannot be overridden by a task
- A lane policy that blocks `git push --force` applies to every agent in that lane
- Pack policies (like quality gates) are enforced by the kernel, not by the agent

### 3. Evidence Receipts

Every tool call produces an **immutable, content-addressed audit record** — what was requested, what scopes were checked, what policies were evaluated, and what the outcome was. Evidence is recorded whether the action succeeds or fails.

This is not logging. It is cryptographic proof of execution that can be independently verified.

### 4. OS-Enforced Isolation

Agents run inside a **bwrap sandbox** with write confinement and deny overlays on secrets. Isolation is enforced by the operating system kernel, not by the agent runtime — agents cannot escape the sandbox even if they try.

## How It Compares

| Aspect                   | No Governance | Prompt-Only (CrewAI) | CI-Only (GitHub Actions) | LumenFlow Kernel                              |
| ------------------------ | ------------- | -------------------- | ------------------------ | --------------------------------------------- |
| **Agent governance**     | None          | Role descriptions    | Post-hoc checks          | 4-level scope intersection, deny-wins         |
| **Evidence of work**     | None          | Conversation logs    | CI logs                  | Immutable content-addressed receipts          |
| **Sandbox isolation**    | None          | None                 | Container-level          | OS-level bwrap with secret deny overlays      |
| **Policy enforcement**   | None          | Prompt suggestions   | Pipeline rules           | Real-time deny-wins cascade                   |
| **Domain extensibility** | N/A           | Custom tools         | Marketplace actions      | Pack system: manifest, scoped tools, policies |

## Domain Packs

LumenFlow's kernel is **domain-agnostic**. It does not know about software delivery, infrastructure provisioning, or compliance auditing. Domain knowledge comes from **packs** — pluggable extensions that teach the kernel how to work in a specific domain.

<CardGrid>
  <Card title="Software Delivery Pack" icon="setting">
    **Built-in.** Work Units, lanes, gates, worktrees, memory, and 100+ CLI commands for structured
    software development.

    [Explore the Software Delivery Pack →](/pack/overview)

  </Card>
  <Card title="Create Your Own Pack" icon="add-document">
    Build a pack for any domain — customer support, data pipelines, infrastructure provisioning,
    compliance auditing. Packs declare tools, policies, and evidence types.

    [Create a Pack →](/guides/create-a-pack)

  </Card>
</CardGrid>

<Aside type="tip">
  Most teams start with the Software Delivery Pack, which ships built-in. If you are a software
  team, [get started here](/guides/manual-quickstart) — everything works out of the box.
</Aside>

## When to Use LumenFlow

**LumenFlow is essential when:**

- AI agents interact with your codebase, infrastructure, or services
- You need an audit trail of what agents did and why
- You want policy enforcement that agents cannot bypass
- You need to prove compliance with security or regulatory requirements
- Multiple agents work in parallel and need coordination boundaries

**LumenFlow may not be needed when:**

- You only use AI for chat-based Q&A (no tool use)
- Agents operate in fully disposable environments with no persistence
- Your existing CI/CD pipeline provides sufficient governance for your risk tolerance

## Philosophy

LumenFlow is built on four principles:

1. **Policy as code** — Governance rules are declarative configurations, not verbal agreements
2. **Evidence over claims** — Immutable receipts prove what happened, not status updates
3. **Continuous governance** — Every action is governed in real-time, not reviewed after the fact
4. **Agents as governed participants** — Agents are first-class team members with the same accountability mechanisms as humans

## Getting Started

<CardGrid>
  <Card title="Humans" icon="rocket">
    Step-by-step setup guide for developers.

    [Get Started →](/guides/manual-quickstart)

  </Card>
  <Card title="AI Agents" icon="seti:robot">
    Canonical setup guide for AI coding assistants.

    [Agent Quickstart →](/getting-started/quickstart)

  </Card>
</CardGrid>

- [What is LumenFlow?](/getting-started/introduction) — Architecture overview
- [Kernel Runtime](/concepts/kernel) — How the kernel dispatches and governs tool calls
- [Packs](/concepts/packs) — The extension mechanism for domain-specific tooling
- [Software Delivery Pack](/pack/overview) — The built-in pack for software teams
