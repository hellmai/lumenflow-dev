// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`WU-1267: Default methodology behavior unchanged (regression) > AC1: Snapshot test captures spawn output with no methodology config > should generate test guidance that matches pre-INIT-009 TDD directive > tdd-directive-default 1`] = `
"## ⛔ TDD DIRECTIVE — READ BEFORE CODING

**IF YOU WRITE IMPLEMENTATION CODE BEFORE A FAILING TEST, YOU HAVE FAILED THIS WU.**

### Test-First Workflow (MANDATORY)

1. Write a failing test for the acceptance criteria
2. Run the test to confirm it fails (RED)
3. Implement the minimum code to pass the test
4. Run the test to confirm it passes (GREEN)
5. Refactor if needed, keeping tests green

### Test Ratchet Rule (WU-1253)

Gates compare test results against \`.lumenflow/test-baseline.json\`:

- **NEW failures** (not in baseline) **BLOCK** gates - you must fix them
- **Pre-existing failures** (in baseline) show **WARNING** - do not block your WU
- When tests are **fixed**, baseline auto-updates (ratchet forward)

If gates fail due to test failures:
1. Check if failure is in baseline: \`cat .lumenflow/test-baseline.json\`
2. If pre-existing: continue, it will warn but not block
3. If NEW: fix the test or add to baseline with reason and fix-wu

### Why This Matters

- Tests document expected behavior BEFORE implementation
- Prevents scope creep and over-engineering
- Ensures every feature has verification
- Failing tests prove the test actually tests something
- Ratchet pattern prevents being blocked by unrelated failures"
`;

exports[`WU-1267: Default methodology behavior unchanged (regression) > AC1: Snapshot test captures spawn output with no methodology config > should produce consistent spawn output when no methodology is configured > spawn-output-no-methodology-config 1`] = `
"<antml:function_calls>
<antml:invoke name="Task">
<antml:parameter name="subagent_type">general-purpose</antml:parameter>
<antml:parameter name="description">Execute WU-REGRESSION</antml:parameter>
<antml:parameter name="prompt">&lt;!-- LUMENFLOW_TRUNCATION_WARNING --&gt;
&lt;!--
  ⚠️ CRITICAL: DO NOT TRUNCATE THIS OUTPUT

  This spawn prompt MUST be copied verbatim. Truncation causes:
  - Missing constraints (agents ignore safety rules)
  - Missing TDD directives (agents skip tests)
  - Degraded agent performance

  VERIFICATION: The output MUST end with: &lt;!-- LUMENFLOW_SPAWN_END --&gt;
  If you don't see that sentinel at the end, the output was truncated.
--&gt;
&lt;task&gt;
Load the following context in this order:

1. Read LUMENFLOW.md (workflow fundamentals and critical rules)
2. Read .lumenflow/constraints.md (non-negotiable constraints)
3. Read README.md (project structure and tech stack)
4. Read docs/04-operations/_frameworks/lumenflow/lumenflow-complete.md sections 1-7 (TDD, gates, Definition of Done)
5. Read docs/04-operations/tasks/wu/WU-REGRESSION.yaml (the specific WU you're working on)
&lt;/task&gt;

---

## ⛔ TDD DIRECTIVE — READ BEFORE CODING

**IF YOU WRITE IMPLEMENTATION CODE BEFORE A FAILING TEST, YOU HAVE FAILED THIS WU.**

### Test-First Workflow (MANDATORY)

1. Write a failing test for the acceptance criteria
2. Run the test to confirm it fails (RED)
3. Implement the minimum code to pass the test
4. Run the test to confirm it passes (GREEN)
5. Refactor if needed, keeping tests green

### Test Ratchet Rule (WU-1253)

Gates compare test results against \`.lumenflow/test-baseline.json\`:

- **NEW failures** (not in baseline) **BLOCK** gates - you must fix them
- **Pre-existing failures** (in baseline) show **WARNING** - do not block your WU
- When tests are **fixed**, baseline auto-updates (ratchet forward)

If gates fail due to test failures:
1. Check if failure is in baseline: \`cat .lumenflow/test-baseline.json\`
2. If pre-existing: continue, it will warn but not block
3. If NEW: fix the test or add to baseline with reason and fix-wu

### Why This Matters

- Tests document expected behavior BEFORE implementation
- Prevents scope creep and over-engineering
- Ensures every feature has verification
- Failing tests prove the test actually tests something
- Ratchet pattern prevents being blocked by unrelated failures

---

# WU-REGRESSION: Test WU

## WU Details

- **ID:** WU-REGRESSION
- **Lane:** Framework: Core
- **Type:** feature
- **Status:** ready
- **Worktree:** worktrees/&lt;lane&gt;-wu-regression

## Description

Test description for regression testing

## Acceptance Criteria

- [ ] Acceptance criterion 1
- [ ] Acceptance criterion 2

## Code Paths

- packages/@lumenflow/core/src/test.ts
---

## Skills Selection

**IMPORTANT**: Before starting work, select and load relevant skills.

### Skills Catalog

Configured skillsDir \`.claude/skills\` was not found. No skills directories configured or found. Set \`directories.skillsDir\` or \`agents.clients.&lt;client&gt;.skillsDir\` in .lumenflow.config.yaml.
### Soft Policy (baselines for this WU)

Based on WU context, consider loading:

- \`wu-lifecycle\` — ALL WUs need workflow automation
- \`worktree-discipline\` — ALL WUs need path safety
- \`tdd-workflow\` — TDD is mandatory for feature/enhancement WUs

### Additional Skills (load if needed)

| Skill | Use When |
|-------|----------|
| lumenflow-gates | Gates fail, debugging format/lint/typecheck errors |
| bug-classification | Bug discovered mid-WU, need priority classification |
| beacon-compliance | Code touches LLM, prompts, classification |
| prompt-management | Working with prompt templates, golden datasets |
| frontend-design | Building UI components, pages |
| initiative-management | Multi-phase projects, INIT-XXX coordination |
| multi-agent-coordination | Spawning sub-agents, parallel WU work |
| orchestration | Agent coordination, mandatory agent checks |
| ops-maintenance | Metrics, validation, health checks |

### Graceful Degradation

If the skill catalogue is missing or invalid:
- Load baseline skills: \`/skill wu-lifecycle\`, \`/skill tdd-workflow\` (for features)
- Continue with implementation using Mandatory Standards below

---

## Mandatory Standards

- **LumenFlow**: Follow trunk-based flow, WIP=1, worktree discipline
- **TDD**: Failing test first, then implementation, then passing test. 90%+ coverage on new application code
- **Hexagonal Architecture**: Ports-first design. No application -&gt; infrastructure imports
- **SOLID/DRY/YAGNI/KISS**: No over-engineering, no premature abstraction
- **Library-First**: Search context7 before writing custom code. No reinventing wheels
- **Code Quality**: No string literals, no magic numbers, no brittle regexes when libraries exist
- **Worktree Discipline**: ALWAYS use \`pnpm wu:claim\` to create worktrees (never \`git worktree add\` directly). Work ONLY in the worktree, never edit main
- **Documentation**: Update tooling docs if changing tools. Keep docs in sync with code
- **Sub-agents**: Use Explore agent for codebase investigation. Activate mandatory agents as configured for your project

---

## Bug Discovery (Mid-WU Issue Capture)

If you discover a bug or issue **outside the scope of this WU**:

1. **Capture it immediately** using:
   \`\`\`bash
   pnpm mem:create 'Bug: &lt;description&gt;' --type discovery --tags bug,scope-creep --wu WU-REGRESSION
   \`\`\`

2. **Continue with your WU** — do not fix bugs outside your scope
3. **Reference in notes** — mention the mem node ID in your completion notes

### NEVER use wu:create for discovered issues

**Do NOT use \`wu:create\` directly for bugs discovered mid-WU.**

- \`mem:create\` = **capture** (immediate, no human approval needed)
- \`wu:create\` = **planned work** (requires human triage and approval)

Discovered issues MUST go through human triage before becoming WUs.
Using \`wu:create\` directly bypasses the triage workflow and creates
unreviewed work items.

### When to Capture

- Found a bug in code NOT in your \`code_paths\`
- Discovered an issue that would require &gt;10 lines to fix
- Encountered broken behaviour unrelated to your acceptance criteria

### Triage Workflow

After WU completion, bugs can be promoted to Bug WUs by humans:
\`\`\`bash
pnpm mem:triage --wu WU-REGRESSION           # List discoveries for this WU
pnpm mem:triage --promote &lt;node-id&gt; --lane "&lt;lane&gt;"  # Create Bug WU (human action)
\`\`\`

See: https://lumenflow.dev/reference/agent-invocation-guide/ §Bug Discovery

---

## Effort Scaling (When to Spawn Sub-Agents)

Use this heuristic to decide complexity:

| Complexity | Approach | Tool Calls |
|------------|----------|------------|
| **Simple** (single file, &lt;50 lines) | Handle inline | 3-10 |
| **Moderate** (2-3 files, clear scope) | Handle inline | 10-20 |
| **Complex** (4+ files, exploration needed) | Spawn Explore agent first | 20+ |
| **Multi-domain** (cross-cutting concerns) | Spawn specialized sub-agents | Varies |

**Rule**: If you need &gt;30 tool calls for a subtask, consider spawning a sub-agent with a focused scope.

---

## Parallel Tool Calls (Performance)

**IMPORTANT**: Make 3+ tool calls in parallel when operations are independent.

Good examples:
- Reading multiple files simultaneously
- Running independent grep searches
- Spawning multiple Explore agents for different areas

Bad examples:
- Reading a file then editing it (sequential dependency)
- Running tests then checking results (sequential)

Parallelism reduces latency by 50-90% for complex tasks.

---

## Search Strategy (Broad to Narrow)

When exploring the codebase:

1. **Start broad**: Use Explore agent or glob patterns to understand structure
2. **Evaluate findings**: What patterns exist? What's relevant?
3. **Narrow focus**: Target specific files/functions based on findings
4. **Iterate**: Refine if initial approach misses the target

Avoid: Jumping directly to specific file edits without understanding context.

---

## Token Budget Awareness

Context limit is ~200K tokens. Monitor your usage:

- **At 50+ tool calls**: Create a checkpoint (\`pnpm mem:checkpoint --wu WU-REGRESSION\`)
- **At 100+ tool calls**: Consider spawning fresh sub-agent with focused scope
- **Before risky operations**: Always checkpoint first

If approaching limits, summarize progress and spawn continuation agent.

---

## Completion Report Format

When finishing, provide structured output:

\`\`\`
## Summary
&lt;1-3 sentences describing what was accomplished&gt;

## Artifacts
- Files modified: &lt;list&gt;
- Tests added: &lt;list&gt;
- Documentation updated: &lt;list&gt;

## Verification
- Gates: &lt;pass/fail&gt;
- Tests: &lt;X passing, Y failing&gt;

## Blockers (if any)
- &lt;blocker description&gt;

## Follow-up (if needed)
- &lt;suggested next WU or action&gt;
\`\`\`

This format enables orchestrator to track progress across waves.

---

## Agent Coordination (Parallel Work)

### ⚠️ CRITICAL: Use mem:signal, NOT TaskOutput

**DO NOT** use TaskOutput to check agent progress - it returns full transcripts
and causes "prompt too long" errors. Always use the memory layer instead:

\`\`\`bash
# ✅ CORRECT: Compact signals (~6 lines)
pnpm mem:inbox --since 30m

# ❌ WRONG: Full transcripts (context explosion)
# TaskOutput with block=false  &lt;-- NEVER DO THIS FOR MONITORING
\`\`\`

### Automatic Completion Signals

\`wu:done\` automatically broadcasts completion signals. You do not need to
manually signal completion - just run \`wu:done\` and orchestrators will
see your signal via \`mem:inbox\`.

### Progress Signals (Required at Milestones)

**Signal at these milestones** to enable orchestrator visibility:

1. **After each acceptance criterion completed** - helps track progress
2. **When tests first pass** - indicates implementation is working
3. **Before running gates** - signals imminent completion
4. **When blocked** - allows orchestrator to re-allocate or assist

\`\`\`bash
pnpm mem:signal "AC1 complete: tests passing for feature X" --wu WU-REGRESSION
pnpm mem:signal "All tests passing, running gates" --wu WU-REGRESSION
pnpm mem:signal "Blocked: waiting for WU-XXX dependency" --wu WU-REGRESSION
\`\`\`

### Checking Status

\`\`\`bash
pnpm orchestrate:init-status -i INIT-XXX  # Initiative progress (compact)
pnpm mem:inbox --since 1h                  # Recent signals from all agents
pnpm mem:inbox --lane "Experience: Web"    # Lane-specific signals
\`\`\`

---

## Quick Fix Commands

If gates fail, try these before investigating:

\`\`\`bash
pnpm format      # Auto-fix formatting issues
pnpm lint        # Check linting (use --fix for auto-fix)
pnpm typecheck   # Check TypeScript types
\`\`\`

**Use before gates** to catch simple issues early. These are faster than full \`pnpm gates\`.

---

## Lane Selection

When creating new WUs, use the correct lane to enable parallelization:

\`\`\`bash
# Get lane suggestion based on code paths and description
pnpm wu:infer-lane --id WU-XXX

# Or infer from manual inputs
pnpm wu:infer-lane --paths "tools/**" --desc "CLI improvements"
\`\`\`

**Lane taxonomy**: See \`.lumenflow.lane-inference.yaml\` for valid lanes and patterns.

**Why lanes matter**: WIP=1 per lane means correct lane selection enables parallel work across lanes.

---

## Action

**FIRST: Claim this WU before starting work:**

\`\`\`bash
pnpm wu:claim --id WU-REGRESSION --lane "Framework: Core"
cd worktrees/framework-core-wu-regression
\`\`\`

Then implement following all standards above.

**CRITICAL:** Never use \`git worktree add\` directly. Always use \`pnpm wu:claim\` to ensure:
- Event tracking in .lumenflow/state/wu-events.jsonl
- Lane lock acquisition (WIP=1 enforcement)
- Session tracking for context recovery

---

&lt;constraints&gt;
CRITICAL RULES - ENFORCE BEFORE EVERY ACTION:

1. TDD CHECKPOINT (VERIFY BEFORE IMPLEMENTATION)
   - Did you write tests BEFORE implementation?
   - Is there at least one failing test for each acceptance criterion?
   - Never skip the RED phase — failing tests prove the test works

2. ANTI-LOOP GUARD (LumenFlow §7.3)
   - Max 3 attempts per unique error before escalating
   - If same error repeats 3x, STOP and report with full context
   - Retry with different approach, not same command

3. STOP-AND-ASK TRIGGERS (LumenFlow §7.2 - narrow scope)
   - Policy changes, auth/permissions modifications
   - PII/PHI/safety issues, cloud spend, secrets, backups
   - Same error repeats 3x
   - For ordinary errors: fix and retry autonomously (up to 3 attempts)

4. VERIFY COMPLETION before reporting success
   - Run: node packages/@lumenflow/agent/dist/agent-verification.js WU-REGRESSION (from shared checkout)
   - Exit 0 = passed, Exit 1 = INCOMPLETE
   - Never report "done" if verification fails

5. NEVER FABRICATE COMPLETION
   - If blockers remain, report INCOMPLETE
   - If verification fails, summarize failures
   - Honesty over false completion

6. GIT WORKFLOW (CRITICAL - GitHub rules reject merge commits)
   - GitHub REJECTS merge commits on main
   - ALWAYS use \`git rebase origin/main\` before push
   - Push to main via \`git push origin lane/...:main\` (fast-forward only)
   - NEVER use \`git merge\` on main branch
   - Use \`pnpm wu:prep\` from worktree, then \`pnpm wu:done\` from main (WU-1223)

7. MEMORY LAYER COORDINATION (INIT-007)
   - Use \`pnpm mem:checkpoint --wu WU-REGRESSION\` to save progress before risky operations
   - Check \`pnpm mem:inbox --wu WU-REGRESSION\` periodically for parallel signals from other agents
   - Checkpoint triggers (WU-1943): checkpoint after each acceptance criterion completed, checkpoint before gates, checkpoint every 30 tool calls

8. SKIP-GATES AUTONOMY (WU-1142)
   - If gates fail, first check if failure is pre-existing on main: \`git checkout main &amp;&amp; pnpm gates\`
   - If failure exists on main (not your change), use: \`pnpm wu:done --id WU-REGRESSION --skip-gates --reason "pre-existing on main" --fix-wu WU-XXXX\`
   - Do NOT ask for approval - autonomous skip-gates for pre-existing failures is correct
   - This prevents getting stuck on infrastructure debt
&lt;/constraints&gt;

&lt;!-- LUMENFLOW_SPAWN_END --&gt;</antml:parameter>
</antml:invoke>
</antml:function_calls>"
`;
